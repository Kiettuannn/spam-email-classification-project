{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83a5666",
   "metadata": {},
   "source": [
    "# Spam Email Classification with Naive - Bayes Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb47389a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KietKlat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KietKlat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\KietKlat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdadec82",
   "metadata": {},
   "source": [
    "## 1. Read and Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f2df6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/2cls_spam_text_cls.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d00b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store for each column and convert to lists\n",
    "messages = df[\"Message\"].values.tolist()\n",
    "labels = df[\"Category\"].values.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e512b",
   "metadata": {},
   "source": [
    "## Pre-processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f9e1a",
   "metadata": {},
   "source": [
    "### Processing steps:\n",
    "- `Message` -> `Lower case` -> `Punctuation Removal` -> `Tokenize` -> `Remove Stopword` -> `Stemming` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d3152",
   "metadata": {},
   "source": [
    "#### Step 1: Lower case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbeb06d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(text):\n",
    "  return text.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144c0c0",
   "metadata": {},
   "source": [
    "#### Step 2: Punctuation Removal\n",
    "- Eliminates all punctuation marks such as `, . '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8490a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_removal(text):\n",
    "  translator = str.maketrans('', '', string.punctuation)\n",
    "  return text.translate(translator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d095b31",
   "metadata": {},
   "source": [
    "#### Step 3: Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2280c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df25e276",
   "metadata": {},
   "source": [
    "#### Step 4: Remove Stopword\n",
    "- Filters out common words that don't carry significant meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69d9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    # Create a set of English stop words, use set for faster lookup\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "    # Return tokens that are not in the stop words set\n",
    "    return [token for token in tokens if token not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c6fcf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'world', 'test']\n"
     ]
    }
   ],
   "source": [
    "test = \"Hello, world! This is a test.\"\n",
    "print(remove_stopwords(tokenize(punctuation_removal(lower_case(test)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2782b83",
   "metadata": {},
   "source": [
    "#### Step 5: Stemming\n",
    "- Reduces words to their root form, grouping similar words together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05fd987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokens):\n",
    "  stemmer  = nltk.stem.PorterStemmer()\n",
    "  return [stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065f9a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'toy', 'scatter', 'everywher']\n"
     ]
    }
   ],
   "source": [
    "s = \"The cat's toys are scattered everywhere.\"\n",
    "print(stemming(remove_stopwords(tokenize(punctuation_removal(lower_case(s))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72eb2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all preprocessing steps into a single function\n",
    "def preprocess_text(text):\n",
    "  lower_text = lower_case(text)\n",
    "  punctuation_text = punctuation_removal(lower_text)\n",
    "  tokens = tokenize(punctuation_text)\n",
    "  token_rm_sw = remove_stopwords(tokens)\n",
    "  stemmed_tokens = stemming(token_rm_sw)\n",
    "  return stemmed_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d24ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'toy', 'scatter', 'everywher']\n"
     ]
    }
   ],
   "source": [
    "s = \"The cat's toys are scattered everywhere.\"\n",
    "print(preprocess_text(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deac552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing the dataset\n",
    "messages = [preprocess_text(message) for message in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f637265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', 'jurong', 'point', 'crazi', 'avail', 'bugi', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'got', 'amor', 'wat'], ['ok', 'lar', 'joke', 'wif', 'u', 'oni'], ['free', 'entri', '2', 'wkli', 'comp', 'win', 'fa', 'cup', 'final', 'tkt', '21st', 'may', '2005', 'text', 'fa', '87121', 'receiv', 'entri', 'questionstd', 'txt', 'ratetc', 'appli', '08452810075over18'], ['u', 'dun', 'say', 'earli', 'hor', 'u', 'c', 'alreadi', 'say'], ['nah', 'dont', 'think', 'goe', 'usf', 'live', 'around', 'though']]\n"
     ]
    }
   ],
   "source": [
    "print(messages[:5])  # Display the first 5 preprocessed messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab275f9",
   "metadata": {},
   "source": [
    "### Create a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1099174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(messages):\n",
    "  dictionary = []\n",
    "  for tokens in messages:\n",
    "    for token in tokens:\n",
    "      if token not in dictionary:\n",
    "        dictionary.append(token)\n",
    "  return dictionary\n",
    "\n",
    "dictionary = create_dictionary(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e382cec0",
   "metadata": {},
   "source": [
    "### Create a features vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "722704e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(tokens, dictionary):\n",
    "  features = np.zeros(len(dictionary))\n",
    "  for token in tokens:\n",
    "    if token in dictionary:\n",
    "      features[dictionary.index(token)] += 1\n",
    "  return features\n",
    "\n",
    "X = np.array([create_features(tokens, dictionary) for tokens in messages])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973d4206",
   "metadata": {},
   "source": [
    "### Pre-processing label data\n",
    "- ham -> 0\n",
    "- spam -> 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bd3ace3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['ham' 'spam']\n",
      "Encoded labels: [0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "print(f\"Classes: {le.classes_}\")\n",
    "print(f\"Encoded labels: {y}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a046df05",
   "metadata": {},
   "source": [
    "## Divide the dataset into: Train, Validation, Test with the rate: 70, 20, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fbc35fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE = 0.2\n",
    "TEST_SIZE = 0.125 # 0.1/(1-0.2)\n",
    "SEED = 0\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=VAL_SIZE, shuffle=True, random_state=SEED)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=TEST_SIZE, shuffle=True, random_state=SEED)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512fc86",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3daac37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "gaussNB = GaussianNB()\n",
    "print(\"Training the model...\")\n",
    "model = gaussNB.fit(X_train, y_train)\n",
    "print(\"Model trained successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84951e77",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37b673bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy: 0.8816\n",
      "Test accuracy: 0.8602\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Val accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b5a51",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fceb4df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for 'I am actually thinking a way of doing something useful': ham\n"
     ]
    }
   ],
   "source": [
    "def predict(text, model, dictionary, label_encoder):\n",
    "  processed_text = preprocess_text(text)\n",
    "  features = create_features(processed_text, dictionary)\n",
    "  features = np.array(features).reshape(1, -1)  # Reshape for single sample\n",
    "  prediction = model.predict(features)\n",
    "  prediction_cls = label_encoder.inverse_transform(prediction)[0]\n",
    "  return prediction_cls\n",
    "\n",
    "# Example usage\n",
    "test_input = \"I am actually thinking a way of doing something useful\"\n",
    "prediction_cls = predict(test_input,model, dictionary, le)\n",
    "print(f\"Prediction for '{test_input}': {prediction_cls}\")\n",
    "\n",
    "   \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam-email-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
